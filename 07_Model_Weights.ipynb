{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of Vocab Size on Predictions\n",
    "\n",
    "In this notebook I pick a classifier and see how the size of the vocabulary impacts predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/nadimkawwa/Desktop/android\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path.cwd()\n",
    "print(f\"Current working directory: {cwd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(pathlib.Path.joinpath(cwd,\n",
    "                                            'data',\n",
    "                                            'cleaned_data',\n",
    "                                            'X_train_clean.csv'),\n",
    "                      index_col=0)\n",
    "y_train = pd.read_csv(pathlib.Path.joinpath(cwd,\n",
    "                                            'data',\n",
    "                                            'cleaned_data',\n",
    "                                            'y_train_clean.csv'),\n",
    "                      index_col=0)\n",
    "\n",
    "#to silence warnings\n",
    "#y_train = np.ravel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(pathlib.Path.joinpath(cwd,\n",
    "                                            'data',\n",
    "                                            'cleaned_data',\n",
    "                                            'X_test_clean.csv'),\n",
    "                      index_col=0)\n",
    "y_test = pd.read_csv(pathlib.Path.joinpath(cwd,\n",
    "                                            'data',\n",
    "                                            'cleaned_data',\n",
    "                                            'y_test_clean.csv'),\n",
    "                      index_col=0)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixes Attribute Error when fitting\n",
    "X_train['description'] = X_train['description'].astype(str)\n",
    "X_test['description'] = X_test['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['.//Min_SDK', './/Min_Screen', './/Min_OpenGL', 'description',\n",
       "       'rating_number', 'rating_count', 'android.permission.BIND_WALLPAPER',\n",
       "       'android.permission.FORCE_BACK', 'android.permission.READ_CALENDAR',\n",
       "       'android.permission.BODY_SENSORS',\n",
       "       ...\n",
       "       'android.permission.SET_ACTIVITY_WATCHER',\n",
       "       'android.permission.READ_SMS', 'android.permission.BATTERY_STATS',\n",
       "       'android.permission.GLOBAL_SEARCH',\n",
       "       'android.permission.BIND_NFC_SERVICE',\n",
       "       'android.permission.PACKAGE_USAGE_STATS',\n",
       "       'android.permission.SET_ALWAYS_FINISH', 'android.permission.ACCESS_DRM',\n",
       "       'android.permission.BROADCAST_STICKY',\n",
       "       'android.permission.MOUNT_UNMOUNT_FILESYSTEMS'],\n",
       "      dtype='object', length=170)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X_train.select_dtypes(exclude= 'object').columns\n",
    "text_columns = X_train.select_dtypes(include= 'object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler',MinMaxScaler()\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "text_transformer = Pipeline(steps=[\n",
    "    ('cntvec',TfidfVectorizer(encoding='utf-8',\n",
    "                                 decode_error='strict',\n",
    "                                 strip_accents='ascii',\n",
    "                                 lowercase=True,\n",
    "                                 analyzer='word',\n",
    "                                 stop_words='english',\n",
    "                                 token_pattern=r'(?u)\\b\\w\\w+\\b',\n",
    "                                 ngram_range=(1,3),\n",
    "                                 #max_df=0.8, \n",
    "                                 #min_df=0.1, \n",
    "                                 max_features=200,\n",
    "                                 use_idf=True, \n",
    "                                 smooth_idf=True))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('numeric',\n",
    "     numeric_transformer,\n",
    "     numeric_columns\n",
    "    ),\n",
    "    ('text',\n",
    "     text_transformer,\n",
    "     text_columns[0]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5560, 369)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans = preprocessor.fit_transform(X_train, y_train)\n",
    "\n",
    "X_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate classifier\n",
    "lr = LogisticRegression(penalty='l2',\n",
    "                                C=1.0, \n",
    "                                class_weight='balanced',\n",
    "                                solver='liblinear'\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  Index(['.//Min_SDK', './/Min_Screen', './/Min_OpenGL', 'rating_number',\n",
       "       'rating_count', 'android.permission.BIND_WALLPAPER',\n",
       "       'android.permission.FORCE_BACK', 'android.permission.READ_CALENDAR',\n",
       "       'android.permission.BODY_SENSORS',\n",
       "       'android.pe...\n",
       "       'android.permission.SET_ALWAYS_FINISH', 'android.permission.ACCESS_DRM',\n",
       "       'android.permission.BROADCAST_STICKY',\n",
       "       'android.permission.MOUNT_UNMOUNT_FILESYSTEMS'],\n",
       "      dtype='object', length=169)),\n",
       "                                                 ('text',\n",
       "                                                  Pipeline(steps=[('cntvec',\n",
       "                                                                   TfidfVectorizer(max_features=200,\n",
       "                                                                                   ngram_range=(1,\n",
       "                                                                                                3),\n",
       "                                                                                   stop_words='english',\n",
       "                                                                                   strip_accents='ascii'))]),\n",
       "                                                  'description')])),\n",
       "                ('clf',\n",
       "                 LogisticRegression(class_weight='balanced',\n",
       "                                    solver='liblinear'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define pipeline for lr\n",
    "pipeline_lr = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', lr )\n",
    "])\n",
    "\n",
    "#fit to train data per new params\n",
    "pipeline_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copied verbatim from here:\n",
    "https://johaupt.github.io/scikit-learn/tutorial/python/data%20processing/ml%20pipeline/model%20interpretation/columnTransformer_feature_names.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from all transformers.\n",
    "    Returns\n",
    "    -------\n",
    "    feature_names : list of strings\n",
    "        Names of the features produced by transform.\n",
    "    \"\"\"\n",
    "    # Remove the internal helper function\n",
    "    #check_is_fitted(column_transformer)\n",
    "    \n",
    "    # Turn loopkup into function for better handling with pipeline later\n",
    "    def get_names(trans):\n",
    "        # >> Original get_feature_names() method\n",
    "        if trans == 'drop' or (\n",
    "                hasattr(column, '__len__') and not len(column)):\n",
    "            return []\n",
    "        if trans == 'passthrough':\n",
    "            if hasattr(column_transformer, '_df_columns'):\n",
    "                if ((not isinstance(column, slice))\n",
    "                        and all(isinstance(col, str) for col in column)):\n",
    "                    return column\n",
    "                else:\n",
    "                    return column_transformer._df_columns[column]\n",
    "            else:\n",
    "                indices = np.arange(column_transformer._n_features)\n",
    "                return ['x%d' % i for i in indices[column]]\n",
    "        if not hasattr(trans, 'get_feature_names'):\n",
    "        # >>> Change: Return input column names if no method avaiable\n",
    "            # Turn error into a warning\n",
    "            warnings.warn(\"Transformer %s (type %s) does not \"\n",
    "                                 \"provide get_feature_names. \"\n",
    "                                 \"Will return input column names if available\"\n",
    "                                 % (str(name), type(trans).__name__))\n",
    "            # For transformers without a get_features_names method, use the input\n",
    "            # names to the column transformer\n",
    "            if column is None:\n",
    "                return []\n",
    "            else:\n",
    "                return [name + \"__\" + f for f in column]\n",
    "\n",
    "        return [name + \"__\" + f for f in trans.get_feature_names()]\n",
    "    \n",
    "    ### Start of processing\n",
    "    feature_names = []\n",
    "    \n",
    "    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n",
    "    if type(column_transformer) == Pipeline:\n",
    "        l_transformers = [(name, trans, None, None) for step, name, trans in column_transformer._iter()]\n",
    "    else:\n",
    "        # For column transformers, follow the original method\n",
    "        l_transformers = list(column_transformer._iter(fitted=True))\n",
    "    \n",
    "    \n",
    "    for name, trans, column, _ in l_transformers: \n",
    "        if type(trans) == Pipeline:\n",
    "            # Recursive call on pipeline\n",
    "            _names = get_feature_names(trans)\n",
    "            # if pipeline has no transformer that returns names\n",
    "            if len(_names)==0:\n",
    "                _names = [name + \"__\" + f for f in column]\n",
    "            feature_names.extend(_names)\n",
    "        else:\n",
    "            feature_names.extend(get_names(trans))\n",
    "    \n",
    "    return np.array(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-960828fae99f>:30: UserWarning: Transformer scaler (type MinMaxScaler) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\"Transformer %s (type %s) does not \"\n"
     ]
    }
   ],
   "source": [
    "#get feature names\n",
    "feat_names = get_feature_names(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get standard dev of each transformed col\n",
    "col_std = np.std(X_trans, axis=0)\n",
    "col_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_coef = pipeline_lr['clf'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_weights = np.multiply(lr_coef, col_std).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_arg = 5\n",
    "weight_least = np.argsort(lr_weights)[:k_arg]\n",
    "weight_most = np.argsort(lr_weights)[-k_arg:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 49,  85,   0, 149, 322])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([104, 129,  91,  24, 127])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following have the strongest indicator AGAISNT malware:\n",
      "\n",
      "numeric__android.permission.BLUETOOTH\n",
      "numeric__android.permission.READ_LOGS\n",
      "numeric__.//Min_SDK\n",
      "numeric__android.permission.READ_EXTERNAL_STORAGE\n",
      "cntvec__ringtones\n"
     ]
    }
   ],
   "source": [
    "print(\"The following have the strongest indicator AGAISNT malware:\\n\")\n",
    "for name in feat_names[weight_least]:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following have the strongest indicator FOR malware:\n",
      "\n",
      "numeric__android.permission.RECEIVE_BOOT_COMPLETED\n",
      "numeric__com.android.launcher.permission.UNINSTALL_SHORTCUT\n",
      "numeric__android.permission.MANAGE_ACCOUNTS\n",
      "numeric__android.permission.WRITE_SYNC_SETTINGS\n",
      "numeric__android.permission.READ_SYNC_SETTINGS\n"
     ]
    }
   ],
   "source": [
    "print(\"The following have the strongest indicator FOR malware:\\n\")\n",
    "for name in feat_names[weight_most]:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.694552665566138"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_weights[127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.22347267087203546"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_weights[322]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_write_sync = X_train[X_train['android.permission.WRITE_SYNC_SETTINGS']==0].index\n",
    "write_sync = X_train[X_train['android.permission.WRITE_SYNC_SETTINGS']==1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL    0.116932\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.loc[no_write_sync].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL    0.988579\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.loc[write_sync].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
